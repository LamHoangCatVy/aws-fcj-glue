[
{
	"uri": "//localhost:1313/",
	"title": "Glue Series",
	"tags": [],
	"description": "",
	"content": "Table of Contents Introduction to Glue Service "
},
{
	"uri": "//localhost:1313/intro/",
	"title": "Introduction to Glue",
	"tags": [],
	"description": "",
	"content": "Objectives: How AWS Glue works Which problems AWS Glue solves The benefits of AWS Glue AWS Glue pricing "
},
{
	"uri": "//localhost:1313/intro/1-1-intro-glue/",
	"title": "1-Intro",
	"tags": [],
	"description": "",
	"content": "What does AWS Glue do? AWS Glue is a serverless data integration service, which means that you only pay for usage and don\u0026rsquo;t pay for idle time. With AWS Glue, data scientists, analysts, and developers can discover, prepare, and combine data for various purposes. Examples includes analytics, machine learning (ML), and application development. AWS Glue provides visual and code-based interfaces for data integration activity and transforms data using built-in transformations.\nYou can quickly locate and access data through the AWS Glue Data Catalog. Data engineers and extract, transform, and lead (ETL) developers can create, run, and monitor ETL workflows using AWS Glue Studio. Data analysts can use the no-code capabilities of AWS Glue DataBrew to enrich, clean, and normalize data without writing any code. Data scientists can use AWS Glue interactive notebooks to quickly start querying their data for interactive analysis, rather than spending months creating infrastructure.\n"
},
{
	"uri": "//localhost:1313/intro/1-2-problems-solved/",
	"title": "1.2 Problems",
	"tags": [],
	"description": "",
	"content": "Which problems does AWS Glue solve? Provisions and manages the lifecycle of resources AWS Glue provisions the requested resources like servers, storage, and runtime environment that ETL jobs need. It also manages the lifecycle of these resources and removes them when they are not being used. AWS Glue maintains the resource pool from where requested capacity is allocated.\nProvides interactive tools AWS Glue has tools for each persona for performing development activities that include no-code, low-code, and interactive tools, so it reduces development time.\nAuto-generates code AWS Glue auto-generates code when built-in transformation are used, which is optimized for runtime and cost effectiveness. It also provides features to upload the scripts to make migration more straightforward.\nConnects to hundreds of data stores AWS Glue connects to hundreds of data stores, including Amazon Redshift, relational databases, MongoDB, and software as a service (SaaS) providers like Salesforce. it also exposes APIs to conveniently build your own connectors.\nCreates a data catalog for various data sources AWS Glue provides the opportunity to create a data catalog for various data sources that could help search metadata and classify data. AWS Glue Data Catalog is used by multiple analytics services to work on the data.\nIdentifies sensitive data using ML recognition patterns for PII AWS Glue helps in identifying sensitive data using ML recognition patterns for personally identifiable information (PII). After identification, you can remediate them by redacting through string or cryptographic hashing.\nManage and enforce schemas on data-streaming applications Using AWS Glue, you can also manage and enforce schemas on data-streaming applications. Integrations with Apache Kafka and Amazon Kinesis help ensure that downstream systems are not affected by semantic changes in upstream systems.\nOffers data quality and automatic data scaling AWS Glue offers data quality for creating and applying built-in rule types or custom rule types to clean and normalize your data. AWS Glue automatically scales as the volume of data increases, and it is integrated with Amazon CloudWatch for monitoring.\n"
},
{
	"uri": "//localhost:1313/intro/1-3-benefits/",
	"title": "1.3 Benefits",
	"tags": [],
	"description": "",
	"content": "What are the benefits of AWS Glue? Faster data integration With AWS Glue, developers have the flexibility to choose their preferred tool for data preparation and processing. This makes it possible to quickly deliver data for analytics, ML, and application development. By creating repeatable and reusable workflows, developers can streamline data integration and ETL processes, making collaboration on these tasks more efficient.\nData engineers can develop and test your AWS Glue job scripts thorugh multiple options\nAWS Glue Studio console Visual editor Script editor AWS Glue Studio notebook Interactive sessions Jupyter Notebook Docker image Local development Remote development AWS Glue Studio ETL library Local development Automate data integration at scale AWS Glue uses crawlers to scan data sources, identify data format and metadata, register the data\u0026rsquo;s schema, and generate code for transformations. It also provide workflows that developers can use to create streamlined and advanced pipelines for ETL tasks.\nNo infrastructure to manage AWS Glue helps you prepare and work on data without users needing to provision and maintain any infrastructure. This makes AWS Glue serverless, because AWS will manage and provision servers from a warm pool. It automatically scales resources up and down as required by AWS Glue jobs. By doing this, data engineers and developers can focus on writing business logic and creating complex workflows. AWS Glue works with contiunous integration and continuous delivery (CI/CD) and also with alerting or monitoring services to make their workload self-service.\nCreate, run, and monitor ETL jobs without coding AWS Glue Studio provides straightforward creation, running and monitoring of ETL tasks for data transformation through a user-friendly drag-and-drop interface. It automatically generates code and offers built-in transformations from AWS Glue DataBrew that can assist with data cleaning and standardization. The processed data can then be used for analytical and ML purpsoes\nPay only for what you use With AWS Glue, users pay only for the resources they consume. There\u0026rsquo;s no upfront cost, and users are not charged for a start-up or shutdown time\n"
},
{
	"uri": "//localhost:1313/intro/1-4-engine-support/",
	"title": "1.4. Engine Support",
	"tags": [],
	"description": "",
	"content": "What is the data integration engine supported by AWS Glue? AWS Glue for Apache Spark Apache Spark is an open-source distributed framework that makes it possible to write transformations for batch and streaming data in Python and Scala. With Spark SQL, developers can write SQL-like queries on big data. Apache Spark also provides ML libraries that run in distributed platforms.\nAWS Glue for Python AWS Glue for Python gives analytics users a Python shell environment to run their Python scripts with the latest Python version\nAWS Glue for Ray Ray (ray.io) is a new open-source compute framework that helps you scale Python workloads. AWS Glue for Ray facilitates the distributed processing of Python code over multi-node clusters. Users can create and run Ray jobs without trying to learn any big-data framework. Ray is a popular tool being used to parallelize complex transformations that are common among ML workloads.\n"
},
{
	"uri": "//localhost:1313/intro/1-5-pricing/",
	"title": "1.5 Pricing",
	"tags": [],
	"description": "",
	"content": "How much does AWS Glue cost (Q3/2023 Update) AWS Glue ETL jobs and interactive sessions With AWS Glue, there are no upfront fees or costs for maintaining infrastructure andd no charges for starting up or shutting down. Users only pay for what they use, which means charges are only applied to job runs. The cost is based on an hourly rate that is rounded to the nearest second, calcualted based on the number of DPUs used to run your ETL job. AWS Glue offers different worker types with varying capacities, including:\nStandard G.1X G.2X G.025X One DPU is equivalent to 4 vCPUs and 16 GB of memory\nUsers can use AWS Glue interactive sessions for interactive ETL code development, but they only incur charges if they decide to run some transformations as a job. The duration of the session determines the cost of interactive sessions and the amount of DPUs used. Interactive sessions can be set with adjustable idle timeouts, and are billed a minimum of 1 minutes.\nInteractive sessions require a minimum of 2 DPUs, with a default of 5 DPUs.\nAWS Glue Studio allows data previews to test your transformations during the job authoring process.\nEach AWS Glue Studio data preview session uses 2 DPUs, runs for 30 minutes, and stops automatically.\nData catalog and storage requests With Data Catalog, you have a free tier to store a certain number of metadata objects such as tables, table versions, partitions, and databases. If you exceed this limit, you will incur charges based on the number of additional objects you store over the free tier.\nThe pricing is applied on a per-object basis and is based on the number of objects exceeding the free-tier limit.\nThe charges apply only to the Data Catalog and not to any other AWS services that you may use with it\nAWS Glue crawlers AWS Glue crawlers incur an hourly charge for discovering data and updating the Data Catalog based on the number of DPUs used. The crawler is billed in 1-second increments, with a minimum of 10 minutes for each crawl, and rounded up to the nearest second.\nUsing AWS Glue crawlers optional, and users can populate the Data Catalog directly through the API\nDataBrew interactive sessions DataBrew jobs AWS Glue Flex execution AWS Glue Data Quality AWS Glue Schema Registry "
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]